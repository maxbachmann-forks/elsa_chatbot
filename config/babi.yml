%YAML 1.2
---
#app setting
APPNAME: END2END_DEMO


# for adversary chatbot
rule_based:
    dialog_file: data/babi/babi_adversary.xlsx 
    
    tokenizer:
        bert_model_name: /home/pzhu/data/bert/bert-base-uncased/vocab
      
    embedding:
        w2v_word2idx: /home/pzhu/data/bert/bert-base-uncased/word2idx.zpkl
        w2v_idx2vec: /home/pzhu/data/bert/bert-base-uncased/word2vec_weight.npy
        dim: 768

    vocab:
        cached_vocab: data/babi/vocab_adversary.pkl

    hook_keywords:
        PARTY_SIZE: data/babi/entities/party_size.txt
        LOCATION: data/babi/entities/location.txt
        CUISINE: data/babi/entities/cuisine.txt
        REST_TYPE: data/babi/entities/rest_type.txt
    
    logger:
        LogLevel_Console:  20
        LogLevel_File: 0
        LogFile: data/babi/train.log
        LogFormat: '%(asctime)s | %(levelname)s: %(message)s'
    
    min_score: 0.6 #jump the rule if less than this score

#
response_template: 
    data: data/babi/template.txt
    cached_index: data/babi/template.index
    cached_vocab: data/babi/vocab_template.pkl
    vocab_size: 100000
    ngrams: 3


ner:
    LANGUAGE: en
    TOKENIZER: spacy
    w2v_word2idx: /home/pzhu/data/word2vec/en/word2idx_2000000.pp
    w2v_idx2vec: /home/pzhu/data/word2vec/en/weight_2000000.npy
    cached_vocab: data/babi/vocab.pkl
    vocab_size: 100000
    cached_w2v: data/babi/w2v.pkl
    vec_len: 300
    annoy_filter: 0.8
    stopwords_path: config/en_stopwords.txt
    entity_dict: data/babi/entity.dict
    max_entity_types: 6
    ner_name_replace:
    ner:
    keywords:
        PARTY_SIZE: data/babi/entities/party_size.txt
        LOCATION: data/babi/entities/location.txt
        CUISINE: data/babi/entities/cuisine.txt
        REST_TYPE: data/babi/entities/rest_type.txt
    regex:  
        REST_INFO: 'resto_\w*'


model:
    use_gpu: 1
    max_seq_len: 10
    max_dialog_len: 20
    dropout: 0.8
    max_entity_types: 6
    cnn_kernel_size: 5
    cnn_kernel_num: 16
    fc_response1: 8
    fc_response2: 4
    learning_rate: 0.001
    weight_decay: 0.0001
    epochs: 10000
    batch_size: 100
    rl_learning_rate: 0.0001
    rl_maxloop: 20
    rl_discount: 0.95
    saved_model: 'data/babi/model.pt'

logger:
    LogLevel_Console:  20
    LogLevel_File: 0
    LogFile: data/babi/train.log
    LogFormat: '%(asctime)s | %(levelname)s: %(message)s'

