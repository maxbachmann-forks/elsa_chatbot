{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config {'encoder': {'vocab_size': 30522, 'hidden_size': 768, 'num_hidden_layers': 3, 'num_attention_heads': 3, 'hidden_act': 'gelu', 'intermediate_size': 1024, 'hidden_dropout_prob': 0, 'attention_probs_dropout_prob': 0, 'max_position_embeddings': 512, 'type_vocab_size': 2, 'initializer_range': 0.02, 'layer_norm_eps': 1e-12}, 'decoder': {'num_hidden_layers': 3, 'num_attention_heads': 3, 'intermediate_size': 1024, 'shared_embed': True}}\n",
      "load model from file data/cornell/model_transformer.pt\n"
     ]
    }
   ],
   "source": [
    "#init\n",
    "import torch, numpy, sys\n",
    "sys.path.append(\"..\")\n",
    "from chatbot_end2end.module.interact_session import InteractSession\n",
    "from nlptools.utils import Config\n",
    "import torch.nn as nn\n",
    "\n",
    "cfg = Config(\"../config/elsa.yml\")\n",
    "session = InteractSession.build(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 768])\n",
      "torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "skill_name = \"cornell\"\n",
    "skill = session.topic_manager.skills[skill_name]\n",
    "state_dict = skill.model.decoder.state_dict()\n",
    "dialog_status = session.new_dialog()\n",
    "dialog_status.add_utterance(\"I would hardly say you look like trash\")\n",
    "data = dialog_status.status2data()\n",
    "\n",
    "encoder_out, encoder_hidden = skill.model.dialog_embedding(data[\"utterance\"].data, data[\"utterance_mask\"].data, data[\"sentiment\"].data)\n",
    "utterance_mask = data[\"utterance_mask\"].data\n",
    "print(encoder_out.shape)\n",
    "print(utterance_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config {'encoder': {'vocab_size': 30522, 'hidden_size': 768, 'num_hidden_layers': 3, 'num_attention_heads': 3, 'hidden_act': 'gelu', 'intermediate_size': 1024, 'hidden_dropout_prob': 0, 'attention_probs_dropout_prob': 0, 'max_position_embeddings': 512, 'type_vocab_size': 2, 'initializer_range': 0.02, 'layer_norm_eps': 1e-12}, 'decoder': {'num_hidden_layers': 1, 'num_attention_heads': 3, 'intermediate_size': 1024, 'shared_embed': True}}\n",
      "tensor([[ 101, 2053, 4283, 2000, 2017, 1012,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]]) [-0.03192614]\n",
      "no thanks to you .\n"
     ]
    }
   ],
   "source": [
    "import nlptools.zoo.encoders.transformer\n",
    "import chatbot_end2end.model.generative_tracker\n",
    "import importlib\n",
    "importlib.reload(nlptools.zoo.encoders.transformer)\n",
    "importlib.reload(chatbot_end2end.model.generative_tracker)\n",
    "\n",
    "from nlptools.zoo.encoders.transformer import TransformerDecoder\n",
    "from chatbot_end2end.model.generative_tracker import GenerativeTracker\n",
    "\n",
    "embedding = skill.model.encoder.embedding\n",
    "\n",
    "decoder_hidden_layers = skill.model.config[\"decoder\"][\"num_hidden_layers\"]\n",
    "decoder_attention_heads = skill.model.config[\"decoder\"][\"num_attention_heads\"]\n",
    "decoder_hidden_size = skill.model.config[\"decoder\"][\"intermediate_size\"]\n",
    "\n",
    "# bert_model_name = skill.model.config[\"bert_model_name\"]\n",
    "pad_id = skill.model.pad_id\n",
    "bos_id = skill.model.bos_id\n",
    "eos_id = skill.model.eos_id\n",
    "unk_id = skill.model.unk_id\n",
    "beam_size = 3\n",
    "len_penalty = 1\n",
    "unk_penalty = 1\n",
    "dropout=0\n",
    "\n",
    "shared_layers = {\"encoder\": skill.model.encoder}\n",
    "\n",
    "tracker = GenerativeTracker(shared_layers=shared_layers, skill_name=skill_name, decoder_hidden_laers=decoder_hidden_layers,\n",
    "                             decoder_attention_heads=decoder_attention_heads, decider_hidden_size=decoder_hidden_size, dropout=dropout, pad_id=pad_id, bos_id=bos_id,\n",
    "                            eos_id=eos_id, unk_id=unk_id, beam_size=beam_size, len_penalty=len_penalty, unk_penalty=unk_penalty)\n",
    "#tracker = tracker.to(\"cuda:0\")\n",
    "\n",
    "decoder = TransformerDecoder(embedding, decoder_hidden_layers, decoder_attention_heads, decoder_hidden_size, dropout)\n",
    "#decoder = decoder.to(\"cuda:0\")\n",
    "decoder.load_state_dict(state_dict)\n",
    "\n",
    "tracker.decoder = decoder\n",
    "\n",
    "result, score = tracker.beam_search(encoder_out, encoder_hidden, utterance_mask)\n",
    "print(result, score)\n",
    "response = result[0].detach().numpy()\n",
    "response = response[response>0][1:-1]\n",
    "response = skill.tokenizer.tokens2sentence(skill.vocab.id2words(response))\n",
    "score = score.item()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
