{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config {'encoder': {'vocab_size': 30522, 'hidden_size': 768, 'intermediate_size': 1024, 'num_hidden_layers': 3, 'bidirectional': True}, 'decoder': {'num_hidden_layers': 3, 'intermediate_size': 1024, 'shared_embed': True, 'max_seq_len': 20, 'attention': True}}\n",
      "load model from file data/cornell/model_gru.pt\n"
     ]
    }
   ],
   "source": [
    "#init\n",
    "import torch, numpy, sys\n",
    "sys.path.append(\"..\")\n",
    "from chatbot_end2end.module.interact_session import InteractSession\n",
    "from nlptools.utils import Config\n",
    "import torch.nn as nn\n",
    "\n",
    "cfg = Config(\"../config/elsa_gru.yml\")\n",
    "session = InteractSession.build(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20, 768]) torch.Size([3, 1, 768])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 19]) torch.Size([19])\n"
     ]
    }
   ],
   "source": [
    "skill_name = \"cornell\"\n",
    "skill = session.topic_manager.skills[skill_name]\n",
    "state_dict = skill.model.decoder.state_dict()\n",
    "dialog_status = session.new_dialog()\n",
    "dialog_status.add_utterance(\"I would hardly say you look like trash\")\n",
    "dialog_status.add_response(\"No thanks to you.\")\n",
    "data = dialog_status.status2data()\n",
    "\n",
    "encoder_out, encoder_hidden = skill.model.dialog_embedding(data[\"utterance\"].data, data[\"utterance_mask\"].data, data[\"sentiment\"].data)\n",
    "utterance_mask = data[\"utterance_mask\"].data\n",
    "prev_output = data['response_cornell'].data[:, :-1]\n",
    "target_output = data['response_cornell'].data[:, 1:]\n",
    "target_output = target_output.unsqueeze(-1).contiguous().view(-1)\n",
    "print(data[\"utterance\"].data.shape)\n",
    "print(encoder_out.shape, encoder_hidden.shape)\n",
    "print(utterance_mask.shape)\n",
    "print(prev_output.shape, target_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': PackedSequence(data=tensor([[nan, nan, nan,  ..., nan, nan, nan]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None),\n",
       " 'utterance': PackedSequence(data=tensor([[  101,  1045,  2052,  6684,  2360,  2017,  2298,  2066, 11669,   102,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None),\n",
       " 'utterance_mask': PackedSequence(data=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None),\n",
       " 'reward': PackedSequence(data=tensor([[0.4750]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None),\n",
       " 'sentiment': PackedSequence(data=tensor([[0.3612, 0.1779]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None),\n",
       " 'response_cornell': PackedSequence(data=tensor([[ 101, 2053, 4283, 2000, 2017, 1012,  102,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None),\n",
       " 'response_mask_cornell': PackedSequence(data=tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder': {'vocab_size': 30522,\n",
       "  'hidden_size': 768,\n",
       "  'intermediate_size': 1024,\n",
       "  'num_hidden_layers': 3,\n",
       "  'bidirectional': True},\n",
       " 'decoder': {'num_hidden_layers': 3,\n",
       "  'intermediate_size': 1024,\n",
       "  'shared_embed': True,\n",
       "  'max_seq_len': 20,\n",
       "  'attention': True}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config {'encoder': {'vocab_size': 30522, 'hidden_size': 768, 'intermediate_size': 1024, 'num_hidden_layers': 3, 'bidirectional': True}, 'decoder': {'num_hidden_layers': 1, 'intermediate_size': 1024, 'shared_embed': True, 'max_seq_len': 20, 'attention': True}}\n",
      "tensor([[ 101, 3685, 2017, 2017, 2017, 2017, 2017, 2017, 2115, 9378, 2115, 2115,\n",
      "         2115, 9378, 9378, 9378, 9378, 9378, 9378, 9378]]) [-0.62449539]\n",
      "cannot you you you you you you your wash your your your wash wash wash wash wash wash\n"
     ]
    }
   ],
   "source": [
    "import nlptools.zoo.encoders.gru\n",
    "import chatbot_end2end.model.generative_tracker\n",
    "import importlib\n",
    "importlib.reload(nlptools.zoo.encoders.gru)\n",
    "importlib.reload(chatbot_end2end.model.generative_tracker)\n",
    "\n",
    "from nlptools.zoo.encoders.gru import GRUDecoder\n",
    "from chatbot_end2end.model.generative_tracker import GenerativeTracker\n",
    "\n",
    "embedding = skill.model.encoder.embedding\n",
    "\n",
    "decoder_hidden_layers = skill.model.config[\"decoder\"][\"num_hidden_layers\"]\n",
    "max_seq_len = skill.model.config[\"decoder\"][\"max_seq_len\"]\n",
    "decoder_hidden_size = skill.model.config[\"decoder\"][\"intermediate_size\"]\n",
    "\n",
    "# bert_model_name = skill.model.config[\"bert_model_name\"]\n",
    "pad_id = skill.model.pad_id\n",
    "bos_id = skill.model.bos_id\n",
    "eos_id = skill.model.eos_id\n",
    "unk_id = skill.model.unk_id\n",
    "beam_size = 1\n",
    "len_penalty = 1\n",
    "unk_penalty = 1\n",
    "dropout=0\n",
    "\n",
    "shared_layers = {\"encoder\": skill.model.encoder}\n",
    "\n",
    "tracker = GenerativeTracker(shared_layers=shared_layers, model_type=\"gru\", skill_name=skill_name, decoder_hidden_laers=decoder_hidden_layers,\n",
    "                             decider_hidden_size=decoder_hidden_size, max_seq_len=max_seq_len, dropout=dropout, pad_id=pad_id, bos_id=bos_id,\n",
    "                            eos_id=eos_id, unk_id=unk_id, beam_size=beam_size, len_penalty=len_penalty, unk_penalty=unk_penalty)\n",
    "\n",
    "decoder = GRUDecoder(embedding, num_hidden_layers=decoder_hidden_layers, intermediate_size=decoder_hidden_size, max_seq_len=max_seq_len, dropout=dropout)\n",
    "decoder.load_state_dict(state_dict)\n",
    "tracker.decoder = decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, score = tracker.beam_search(encoder_out, encoder_hidden, utterance_mask)\n",
    "print(result, score)\n",
    "response = result[0].detach().numpy()\n",
    "response = response[response>0][1:-1]\n",
    "response = skill.tokenizer.tokens2sentence(skill.vocab.id2words(response))\n",
    "score = score.item()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-78.2895, -79.8654, -79.5300,  ..., -74.2396, -66.7165, -70.0399],\n",
      "        [-55.1096, -55.3329, -55.7615,  ..., -48.5555, -43.9671, -42.6813],\n",
      "        [-53.5853, -53.3650, -54.6049,  ..., -46.9380, -47.7513, -48.0000],\n",
      "        ...,\n",
      "        [-44.9050, -45.3993, -46.6519,  ..., -40.5495, -42.0737, -38.5874],\n",
      "        [-44.8530, -45.3739, -46.6146,  ..., -40.4901, -42.0876, -38.5729],\n",
      "        [-44.8117, -45.3576, -46.5866,  ..., -40.4416, -42.1141, -38.5585]],\n",
      "       grad_fn=<ViewBackward>) tensor([2053, 4283, 2000, 2017, 1012,  102,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.852401733398438"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = skill.model.decoder(prev_output, encoder_out=encoder_out, encoder_padding_mask=utterance_mask, encoder_hidden=encoder_hidden)\n",
    "output_probs=skill.model.logsoftmax(output)\n",
    "output_probs_expand = output_probs.contiguous().view(-1, output_probs.size(2))\n",
    "loss = skill.model.loss_function(output_probs_expand, target_output)\n",
    "print(output_probs_expand, target_output)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeTracker(\n",
       "  (encoder): SentenceEncoder(\n",
       "    (encoder): GRUEncoder(\n",
       "      (embeddings): Embedding(30522, 768)\n",
       "      (gru): GRU(768, 1024, num_layers=3, batch_first=True, bidirectional=True)\n",
       "      (linear_out_x): Linear(in_features=2048, out_features=768, bias=True)\n",
       "      (linear_out_hidden): Linear(in_features=2048, out_features=768, bias=True)\n",
       "    )\n",
       "    (embedding): Embedding(30522, 768)\n",
       "  )\n",
       "  (control_layer): Linear(in_features=770, out_features=768, bias=True)\n",
       "  (decoder): GRUDecoder(\n",
       "    (word_embedding): Embedding(30522, 768)\n",
       "    (gru): GRU(768, 1024, num_layers=3, batch_first=True)\n",
       "    (attn): Linear(in_features=1792, out_features=20, bias=True)\n",
       "    (attn_combine): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0)\n",
       "    (hidden_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
       "    (intermediate_linear): Linear(in_features=1024, out_features=768, bias=True)\n",
       "    (output_linear): Linear(in_features=768, out_features=30522, bias=False)\n",
       "  )\n",
       "  (loss_function): NLLLoss()\n",
       "  (logsoftmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
