{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config {'encoder': {'vocab_size': 30522, 'hidden_size': 768, 'intermediate_size': 1024, 'num_hidden_layers': 3, 'bidirectional': True}, 'decoder': {'num_hidden_layers': 3, 'intermediate_size': 1024, 'shared_embed': True, 'max_seq_len': 20, 'attention': True}}\n",
      "load model from file data/cornell/model_gru.pt\n"
     ]
    }
   ],
   "source": [
    "#init\n",
    "import torch, numpy, sys\n",
    "sys.path.append(\"..\")\n",
    "from chatbot_end2end.module.interact_session import InteractSession\n",
    "from nlptools.utils import Config\n",
    "import torch.nn as nn\n",
    "\n",
    "cfg = Config(\"../config/elsa_gru.yml\")\n",
    "session = InteractSession.build(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20, 768]) torch.Size([3, 1, 768])\n",
      "torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "skill_name = \"cornell\"\n",
    "skill = session.topic_manager.skills[skill_name]\n",
    "state_dict = skill.model.decoder.state_dict()\n",
    "dialog_status = session.new_dialog()\n",
    "dialog_status.add_utterance(\"I would hardly say you look like trash\")\n",
    "data = dialog_status.status2data()\n",
    "\n",
    "encoder_out, encoder_hidden = skill.model.dialog_embedding(data[\"utterance\"].data, data[\"utterance_mask\"].data, data[\"sentiment\"].data)\n",
    "utterance_mask = data[\"utterance_mask\"].data\n",
    "print(data[\"utterance\"].data.shape)\n",
    "print(encoder_out.shape, encoder_hidden.shape)\n",
    "print(utterance_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': PackedSequence(data=tensor([[nan, nan, nan,  ..., nan, nan, nan]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None),\n",
       " 'utterance': PackedSequence(data=tensor([[  101,  1045,  2052,  6684,  2360,  2017,  2298,  2066, 11669,   102,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None),\n",
       " 'utterance_mask': PackedSequence(data=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None),\n",
       " 'reward': PackedSequence(data=tensor([[1.]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None),\n",
       " 'sentiment': PackedSequence(data=tensor([[0.3612, 0.0000]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None),\n",
       " 'response_mask_cornell': PackedSequence(data=tensor([[0]]), batch_sizes=tensor([1]), sorted_indices=None, unsorted_indices=None)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder': {'vocab_size': 30522,\n",
       "  'hidden_size': 768,\n",
       "  'intermediate_size': 1024,\n",
       "  'num_hidden_layers': 3,\n",
       "  'bidirectional': True},\n",
       " 'decoder': {'num_hidden_layers': 3,\n",
       "  'intermediate_size': 1024,\n",
       "  'shared_embed': True,\n",
       "  'max_seq_len': 20,\n",
       "  'attention': True}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config {'encoder': {'vocab_size': 30522, 'hidden_size': 768, 'intermediate_size': 1024, 'num_hidden_layers': 3, 'bidirectional': True}, 'decoder': {'num_hidden_layers': 1, 'intermediate_size': 1024, 'shared_embed': True, 'max_seq_len': 20, 'attention': True}}\n"
     ]
    }
   ],
   "source": [
    "import nlptools.zoo.encoders.gru\n",
    "import chatbot_end2end.model.generative_tracker\n",
    "import importlib\n",
    "importlib.reload(nlptools.zoo.encoders.gru)\n",
    "importlib.reload(chatbot_end2end.model.generative_tracker)\n",
    "\n",
    "from nlptools.zoo.encoders.gru import GRUDecoder\n",
    "from chatbot_end2end.model.generative_tracker import GenerativeTracker\n",
    "\n",
    "embedding = skill.model.encoder.embedding\n",
    "\n",
    "decoder_hidden_layers = skill.model.config[\"decoder\"][\"num_hidden_layers\"]\n",
    "max_seq_len = skill.model.config[\"decoder\"][\"max_seq_len\"]\n",
    "decoder_hidden_size = skill.model.config[\"decoder\"][\"intermediate_size\"]\n",
    "\n",
    "# bert_model_name = skill.model.config[\"bert_model_name\"]\n",
    "pad_id = skill.model.pad_id\n",
    "bos_id = skill.model.bos_id\n",
    "eos_id = skill.model.eos_id\n",
    "unk_id = skill.model.unk_id\n",
    "beam_size = 1\n",
    "len_penalty = 1\n",
    "unk_penalty = 1\n",
    "dropout=0\n",
    "\n",
    "shared_layers = {\"encoder\": skill.model.encoder}\n",
    "\n",
    "tracker = GenerativeTracker(shared_layers=shared_layers, model_type=\"gru\", skill_name=skill_name, decoder_hidden_laers=decoder_hidden_layers,\n",
    "                             decider_hidden_size=decoder_hidden_size, max_seq_len=max_seq_len, dropout=dropout, pad_id=pad_id, bos_id=bos_id,\n",
    "                            eos_id=eos_id, unk_id=unk_id, beam_size=beam_size, len_penalty=len_penalty, unk_penalty=unk_penalty)\n",
    "\n",
    "decoder = GRUDecoder(embedding, num_hidden_layers=decoder_hidden_layers, intermediate_size=decoder_hidden_size, max_seq_len=max_seq_len, dropout=dropout)\n",
    "decoder.load_state_dict(state_dict)\n",
    "\n",
    "tracker.decoder = decoder\n",
    "\n",
    "result, score = tracker.beam_search(encoder_out, encoder_hidden, utterance_mask)\n",
    "\n",
    "print(result, score)\n",
    "response = result[0].detach().numpy()\n",
    "response = response[response>0][1:-1]\n",
    "response = skill.tokenizer.tokens2sentence(skill.vocab.id2words(response))\n",
    "score = score.item()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2053, 2017, 2017, 2017, 2079, 2079, 2079, 2079, 2079, 2079, 2079,\n",
       "         2079, 2079, 2079, 2079, 2079, 2079, 2079, 2079]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
